{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Batch_Normalization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xcS6kAMua75"
      },
      "source": [
        "## Loading the Fashion MNIST Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opnBkcdTuh4J"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow import keras"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTA9ATvJo-gK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0a37415-321e-484d-c3ad-ec4dacec302d"
      },
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\r\n",
        "X_train_full = X_train_full / 255.0\r\n",
        "X_test = X_test / 255.0\r\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\r\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 2s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-QjFCq3ue3N"
      },
      "source": [
        "model = keras.models.Sequential([\r\n",
        "                                 keras.layers.Flatten(input_shape=[28,28]),\r\n",
        "                                 keras.layers.BatchNormalization(),\r\n",
        "                                 keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\r\n",
        "                                 keras.layers.BatchNormalization(),\r\n",
        "                                 keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\r\n",
        "                                 keras.layers.BatchNormalization(),\r\n",
        "                                 keras.layers.Dense(10, activation=\"softmax\")\r\n",
        "\r\n",
        "])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5H8XesbVvlF1",
        "outputId": "1c17c26d-0df8-4d24-f722-6950b3f27e3c"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 784)               3136      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 300)               235500    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 300)               1200      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               30100     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 271,346\n",
            "Trainable params: 268,978\n",
            "Non-trainable params: 2,368\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-oA4x4vvzhp"
      },
      "source": [
        "As you can see, each BN layer adds four parameters per input: γ, β, μ, and σ (for example, the first BN layer adds 3,136 parameters, which is 4 × 784). The last two parameters, μ and σ, are the moving averages; they are not affected by backpropaga‐ tion, so Keras calls them “non-trainable”9 (if you count the total number of BN parameters, 3,136 + 1,200 + 400, and divide by 2, you get 2,368, which is the total number of non-trainable parameters in this model). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_p2b9qyv-B9"
      },
      "source": [
        "Let's look at the parameters of the first BN layer. Two are trainable and two are not"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wv4ikEaqvnH5",
        "outputId": "b964cbef-054a-4c9e-ac77-cdde7db47c12"
      },
      "source": [
        "[(var.name, var.trainable) for var in model.layers[1].variables]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('batch_normalization/gamma:0', True),\n",
              " ('batch_normalization/beta:0', True),\n",
              " ('batch_normalization/moving_mean:0', False),\n",
              " ('batch_normalization/moving_variance:0', False)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2VvHfvPwoif"
      },
      "source": [
        "The authors of the BN paper argued in favor of adding the BN layers before the activation functions, rather than after (as we just did). There is some debate about this, as which is preferable seems to depend on the task—you can experiment with this too to see which option works best on your dataset. To add the BN layers before the activation functions, you must remove the activation function from the hidden layers and add them as separate layers after the BN layers. Moreover, since a Batch Normaliza‐ tion layer includes one offset parameter per input, you can remove the bias term from the previous layer (just pass use_bias=False when creating it):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BHHTDKTwWGv"
      },
      "source": [
        "model = keras.models.Sequential([\r\n",
        "                                keras.layers.Flatten(input_shape=[28,28]),\r\n",
        "                                keras.layers.BatchNormalization(),\r\n",
        "                                keras.layers.Dense(300, kernel_initializer=\"he_normal\", use_bias=False),\r\n",
        "                                keras.layers.BatchNormalization(),\r\n",
        "                                keras.layers.Activation(\"elu\"),\r\n",
        "                                keras.layers.Dense(100, kernel_initializer=\"he_normal\", use_bias=False),\r\n",
        "                                keras.layers.BatchNormalization(),\r\n",
        "                                keras.layers.Activation(\"elu\"),\r\n",
        "                                keras.layers.Activation(\"softmax\")\r\n",
        "])"
      ],
      "execution_count": 10,
      "outputs": []
    }
  ]
}